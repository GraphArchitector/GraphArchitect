{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование RLAIF (LLM как судья)\n",
    "\n",
    "Reinforcement Learning from AI Feedback:\n",
    "- LLM оценивает качество ответов\n",
    "- Автоматическое обучение на основе оценок\n",
    "- Измерение улучшения системы\n",
    "\n",
    "Требуется: OPENROUTER_API_KEY или VLLM сервер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " OPENROUTER_API_KEY установлен - будут реальные оценки\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "grapharchitect_path = Path.cwd().parent.parent / \"src\" / \"GraphArchitectLib\"\n",
    "sys.path.insert(0, str(grapharchitect_path))\n",
    "\n",
    "# Проверка API ключа\n",
    "HAS_API_KEY = bool(os.getenv('OPENROUTER_API_KEY'))\n",
    "\n",
    "if HAS_API_KEY:\n",
    "    print(\" OPENROUTER_API_KEY установлен - будут реальные оценки\")\n",
    "else:\n",
    "    print(\"OPENROUTER_API_KEY НЕ установлен - симуляция\")\n",
    "    print(\"  Для реальных оценок: set OPENROUTER_API_KEY=your-key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Создание LLM Критика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:grapharchitect.tools.ApiTools.OpenRouterTool.openrouter_llm:OpenRouter инициализирован: модель openai/gpt-3.5-turbo\n",
      "INFO:grapharchitect.services.rlaif.llm_critic:OpenRouter backend initialized successfully\n",
      "INFO:grapharchitect.services.rlaif.llm_critic:LLM Critic initialized: backend=openrouter, model=openai/gpt-3.5-turbo, detailed=True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LLM Критик создан\n",
      "  Модель: openai/gpt-3.5-turbo\n",
      "  Температура: 0.2\n"
     ]
    }
   ],
   "source": [
    "from grapharchitect.services.rlaif.llm_critic import LLMCritic\n",
    "\n",
    "if HAS_API_KEY:\n",
    "    critic = LLMCritic(\n",
    "        backend=\"openrouter\",\n",
    "        model_name=\"openai/gpt-3.5-turbo\",\n",
    "        temperature=0.2,  # Низкая для consistency\n",
    "        detailed_evaluation=True\n",
    "    )\n",
    "    \n",
    "    print(\" LLM Критик создан\")\n",
    "    print(f\"  Модель: openai/gpt-3.5-turbo\")\n",
    "    print(f\"  Температура: 0.2\")\n",
    "else:\n",
    "    print(\"Симуляция LLM критика\")\n",
    "    critic = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Тест оценки хорошего ответа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Задача: Классифицировать отзыв по тональности: Отзыв \"Отличный товар\"\n",
      "\n",
      "Ответ:\n",
      "[Классификация]\n",
      "Отзыв: ПОЗИТИВНЫЙ\n",
      "\n",
      "Обоснование:\n",
      "- Фразы \"отличный продукт\", \"очень доволен\" указывают на позитив\n",
      "- Нет негативных формулировок\n",
      "- Общий тон восторженный\n",
      "\n",
      "Уверенность: 95%\n",
      "\n",
      "Оценка LLM критиком...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:grapharchitect.tools.ApiTools.OpenRouterTool.openrouter_llm:Использовано токенов: prompt=658, completion=104, total=762\n",
      "INFO:grapharchitect.services.rlaif.llm_critic:Evaluation completed: task_id=None, overall=1.000, correctness=1.000, completeness=1.000, relevance=1.000, clarity=1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты оценки:\n",
      "  Общий балл: 1.00/1.0\n",
      "  Правильность: 1.00\n",
      "  Полнота: 1.00\n",
      "  Релевантность: 1.00\n",
      "  Ясность: 1.00\n",
      "\n",
      "  Обоснование: The answer is correct, complete, relevant, and clear. It accurately classifies the sentiment of the review based on the provided text, considering the positive language used and the absence of negative expressions. The reasoning behind the classification is logical and well-supported.\n"
     ]
    }
   ],
   "source": [
    "task = \"Классифицировать отзыв по тональности: Отзыв \\\"Отличный товар\\\"\"\n",
    "\n",
    "good_answer = \"\"\"[Классификация]\n",
    "Отзыв: ПОЗИТИВНЫЙ\n",
    "\n",
    "Обоснование:\n",
    "- Фразы \"отличный продукт\", \"очень доволен\" указывают на позитив\n",
    "- Нет негативных формулировок\n",
    "- Общий тон восторженный\n",
    "\n",
    "Уверенность: 95%\"\"\"\n",
    "\n",
    "print(f\"Задача: {task}\")\n",
    "print(f\"\\nОтвет:\\n{good_answer}\\n\")\n",
    "\n",
    "if HAS_API_KEY and critic:\n",
    "    print(\"Оценка LLM критиком...\\n\")\n",
    "    \n",
    "    score = critic.evaluate_answer(task, good_answer)\n",
    "    \n",
    "    print(\"Результаты оценки:\")\n",
    "    print(f\"  Общий балл: {score.overall_score:.2f}/1.0\")\n",
    "    print(f\"  Правильность: {score.correctness:.2f}\")\n",
    "    print(f\"  Полнота: {score.completeness:.2f}\")\n",
    "    print(f\"  Релевантность: {score.relevance:.2f}\")\n",
    "    print(f\"  Ясность: {score.clarity:.2f}\")\n",
    "    print(f\"\\n  Обоснование: {score.reasoning}\")\n",
    "else:\n",
    "    print(\"Симуляция оценки: ~0.90 (хороший ответ)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Тест оценки плохого ответа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Задача: Классифицировать отзыв по тональности: Отзыв \"Отличный товар\"\n",
      "\n",
      "Ответ:\n",
      "[Классификация]\n",
      "Отзыв: НЕГАТИВНЫЙ\n",
      "\n",
      "Обоснование:\n",
      "- Фразы \"отличный продукт\", \"очень доволен\" указывают на негатив\n",
      "\n",
      "Уверенность: 95%\n",
      "\n",
      "Оценка LLM критиком...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:grapharchitect.tools.ApiTools.OpenRouterTool.openrouter_llm:Использовано токенов: prompt=631, completion=107, total=738\n",
      "INFO:grapharchitect.services.rlaif.llm_critic:Evaluation completed: task_id=None, overall=0.300, correctness=0.200, completeness=0.200, relevance=0.100, clarity=0.600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты оценки:\n",
      "  Общий балл: 0.30/1.0\n",
      "  Правильность: 0.20\n",
      "  Полнота: 0.20\n",
      "  Релевантность: 0.10\n",
      "  Ясность: 0.60\n",
      "\n",
      "  Обоснование: The answer incorrectly classifies the sentiment of the review and lacks depth in reasoning. It fails to consider the context and sentiment analysis accurately.\n"
     ]
    }
   ],
   "source": [
    "task = \"Классифицировать отзыв по тональности: Отзыв \\\"Отличный товар\\\"\"\n",
    "\n",
    "good_answer = \"\"\"[Классификация]\n",
    "Отзыв: НЕГАТИВНЫЙ\n",
    "\n",
    "Обоснование:\n",
    "- Фразы \"отличный продукт\", \"очень доволен\" указывают на негатив\n",
    "\n",
    "Уверенность: 95%\"\"\"\n",
    "\n",
    "print(f\"Задача: {task}\")\n",
    "print(f\"\\nОтвет:\\n{good_answer}\\n\")\n",
    "\n",
    "if HAS_API_KEY and critic:\n",
    "    print(\"Оценка LLM критиком...\\n\")\n",
    "    \n",
    "    score = critic.evaluate_answer(task, good_answer)\n",
    "    \n",
    "    print(\"Результаты оценки:\")\n",
    "    print(f\"  Общий балл: {score.overall_score:.2f}/1.0\")\n",
    "    print(f\"  Правильность: {score.correctness:.2f}\")\n",
    "    print(f\"  Полнота: {score.completeness:.2f}\")\n",
    "    print(f\"  Релевантность: {score.relevance:.2f}\")\n",
    "    print(f\"  Ясность: {score.clarity:.2f}\")\n",
    "    print(f\"\\n  Обоснование: {score.reasoning}\")\n",
    "else:\n",
    "    print(\"Симуляция оценки: ~0.20 (плохой ответ)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. RLAIF Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m selector \u001b[38;5;241m=\u001b[39m InstrumentSelector(temperature_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m     13\u001b[0m finder \u001b[38;5;241m=\u001b[39m GraphStrategyFinder()\n\u001b[1;32m---> 14\u001b[0m orchestrator \u001b[38;5;241m=\u001b[39m ExecutionOrchestrator(\u001b[43membedding\u001b[49m, selector, finder)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m HAS_API_KEY \u001b[38;5;129;01mand\u001b[39;00m critic:\n\u001b[0;32m     17\u001b[0m     rlaif_trainer \u001b[38;5;241m=\u001b[39m RLAIFTrainer(\n\u001b[0;32m     18\u001b[0m         llm_critic\u001b[38;5;241m=\u001b[39mcritic,\n\u001b[0;32m     19\u001b[0m         training_orchestrator\u001b[38;5;241m=\u001b[39mtraining_orch\n\u001b[0;32m     20\u001b[0m     )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'embedding' is not defined"
     ]
    }
   ],
   "source": [
    "# Создаем полный workflow с обучением\n",
    "from grapharchitect.services.rlaif.rlaif_trainer import RLAIFTrainer\n",
    "from grapharchitect.services.training.training_orchestrator import TrainingOrchestrator\n",
    "from grapharchitect.services.execution.execution_orchestrator import ExecutionOrchestrator\n",
    "from grapharchitect.services.selection.instrument_selector import InstrumentSelector\n",
    "from grapharchitect.services.graph_strategy_finder import GraphStrategyFinder\n",
    "from grapharchitect.entities.task_definition import TaskDefinition\n",
    "from grapharchitect.entities.connectors.connector import Connector\n",
    "\n",
    "# Инициализация\n",
    "training_orch = TrainingOrchestrator(learning_rate=0.02)\n",
    "selector = InstrumentSelector(temperature_constant=1.0)\n",
    "finder = GraphStrategyFinder()\n",
    "orchestrator = ExecutionOrchestrator(embedding, selector, finder)\n",
    "\n",
    "if HAS_API_KEY and critic:\n",
    "    rlaif_trainer = RLAIFTrainer(\n",
    "        llm_critic=critic,\n",
    "        training_orchestrator=training_orch\n",
    "    )\n",
    "    \n",
    "    print(\"RLAIF Trainer инициализирован\")\n",
    "else:\n",
    "    print(\"Симуляция RLAIF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполнение и оценка\n",
    "task_def = TaskDefinition(\n",
    "    description=\"Классифицировать отзыв\",\n",
    "    input_connector=Connector(\"text\", \"question\"),\n",
    "    output_connector=Connector(\"text\", \"answer\"),\n",
    "    input_data=\"Отличный продукт!\"\n",
    ")\n",
    "\n",
    "# Выполнение\n",
    "context = orchestrator.execute_task(task_def, tools[:1], path_limit=1, top_k=1)\n",
    "\n",
    "print(f\"Выполнено: {context.status.value}\")\n",
    "print(f\"Результат: {context.result}\")\n",
    "\n",
    "# RLAIF оценка и обучение\n",
    "if HAS_API_KEY and rlaif_trainer:\n",
    "    print(\"\\nRLAIF оценка и обучение...\")\n",
    "    \n",
    "    result = rlaif_trainer.evaluate_and_train(\n",
    "        context=context,\n",
    "        task_description=task_def.description,\n",
    "        result=context.result\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nОценка: {result.average_score:.2f}\")\n",
    "    print(f\"Инструментов обучено: {result.tools_updated}\")\n",
    "    print(\"\\nИзменения репутации:\")\n",
    "    for tool_name, delta in result.improvements.items():\n",
    "        print(f\"  {tool_name}: {delta:+.4f}\")\n",
    "else:\n",
    "    print(\"\\nСимуляция: Оценка 0.87, репутация +0.0174\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоги\n",
    "\n",
    "**RLAIF протестирован**:\n",
    "- ✓ LLM критик оценивает по 4 критериям\n",
    "- ✓ Автоматическое обучение\n",
    "- ✓ Обновление репутации\n",
    "- ✓ Без участия человека\n",
    "\n",
    "**Преимущества**:\n",
    "- Масштабируемость (тысячи оценок)\n",
    "- Скорость (мгновенная обратная связь)\n",
    "- Стоимость ($0.001-0.01 за оценку)\n",
    "- Consistency (одинаковые критерии)\n",
    "\n",
    "**Применение**:\n",
    "- Автоматическая валидация\n",
    "- Continuous обучение\n",
    "- A/B тестирование инструментов"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
