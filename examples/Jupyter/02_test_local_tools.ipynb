{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование локальных инструментов\n",
    "\n",
    "Локальные инструменты работают без внешних API:\n",
    "- Zero-Shot Classifier\n",
    "- Text Vectorizer  \n",
    "- Audio Recognizer\n",
    "- Video Describer\n",
    "- VQA (Visual Question Answering)\n",
    "\n",
    "Требуется: PyTorch, transformers, модели Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#Если у Вас установлен PyTorch НЕ ЗАПУСКАТЬ\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers>=4.26.0 huggingface_hub>=0.16.0 -q \n",
    "# Обновление библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Только в случае НЕ СОВМЕСТИМОСТИ библиотек\n",
    "!pip uninstall -y torch torchvision torchaudio\n",
    "!pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.3.0+cpu\n",
      "CUDA: False\n",
      "1.23.5\n",
      "2.3.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"CUDA:\", torch.cuda.is_available())\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "print(np.__version__)\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphArchitect добавлен в путь\n"
     ]
    }
   ],
   "source": [
    "# Настройка\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "grapharchitect_path = Path.cwd().parent.parent / \"src\" / \"GraphArchitectLib\"\n",
    "sys.path.insert(0, str(grapharchitect_path))\n",
    "\n",
    "print(\"GraphArchitect добавлен в путь\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-Shot Text Classifier\n",
    "\n",
    "Классификация текста без обучения, используя MNLI модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:faiss.loader:Loading faiss with AVX2 support.\n",
      "INFO:faiss.loader:Could not load library with AVX2 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\n",
      "INFO:faiss.loader:Loading faiss.\n",
      "INFO:faiss.loader:Successfully loaded faiss.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71f51ccccea4717a020cc883873ba61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZZZ\\Documents\\GitHub\\Python\\GraphArchitect\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ZZZ\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb7655cc78ca4e5dac5a7b5c66529ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac36d5c51044599b94132db1f7b09ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0c9f49c4cd4d058df7893bfa26f740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b9a02992e344ef85d603f09e151143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce0450c981e42ceb4957c957140fe3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-Shot Classifier создан\n",
      "  Модель: BartForSequenceClassification(\n",
      "  (model): BartModel(\n",
      "    (shared): Embedding(50265, 1024, padding_idx=1)\n",
      "    (encoder): BartEncoder(\n",
      "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
      "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
      "      (layers): ModuleList(\n",
      "        (0-11): 12 x BartEncoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): GELUActivation()\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): BartDecoder(\n",
      "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
      "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
      "      (layers): ModuleList(\n",
      "        (0-11): 12 x BartDecoderLayer(\n",
      "          (self_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (activation_fn): GELUActivation()\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): BartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (classification_head): BartClassificationHead(\n",
      "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Текст: Отличный продукт, очень доволен!\n",
      "Категории: ['positive', 'negative', 'neutral']\n",
      "\n",
      "Результат: 0.407416969537735\n",
      "\n",
      "Требуется PyTorch и transformers\n",
      "  pip install torch transformers\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from grapharchitect.tools.LocalTools.Classifiers.ZeroShotTextClassifier import ZeroShotClassifier\n",
    "    \n",
    "    # Создание классификатора\n",
    "    classifier = ZeroShotClassifier(\n",
    "        model_or_path=\"facebook/bart-large-mnli\"\n",
    "    )\n",
    "    \n",
    "    print(\"Zero-Shot Classifier создан\")\n",
    "    print(f\"  Модель: {classifier.model}\")\n",
    "    \n",
    "    # Тестовая классификация\n",
    "    text = \"Отличный продукт, очень доволен!\"\n",
    "    labels = [\"positive\", \"negative\", \"neutral\"]\n",
    "    \n",
    "    print(f\"\\nТекст: {text}\")\n",
    "    print(f\"Категории: {labels}\")\n",
    "    \n",
    "    # Раскомментируйте для реального вызова:\n",
    "    result = classifier.classify(text, labels)\n",
    "    print(f\"\\nРезультат: {result}\")\n",
    "    \n",
    "    print(\"\\nТребуется PyTorch и transformers\")\n",
    "    print(\"  pip install torch transformers\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Vectorizer\n",
    "\n",
    "Векторизация текста используя E5 модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb33ea5131a46bfb7cf8440c5add36e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99e03c98d2b4ebe8482db12c622cac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22bd36886f64e14a849b9ae57325046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6cdebfbebe54ed8854408db99a980cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "448e5bb8f2964874bdba804bfcbe1f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d5d38908564e529b3f3513677f4f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Vectorizer создан\n",
      "  Модель: BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-11): 12 x BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n",
      "\n",
      "Тексты для векторизации: 3\n",
      "Эмбеддинги: (3, 768)\n",
      "Сходство 'ML' и 'AI': 0.821\n",
      "\n",
      "Требуется PyTorch и transformers\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from grapharchitect.tools.LocalTools.TextVectorize import TextVectorizer\n",
    "    \n",
    "    # Создание векторайзера\n",
    "    vectorizer = TextVectorizer(\n",
    "        model_or_path=\"intfloat/e5-base-v2\"\n",
    "    )\n",
    "    \n",
    "    print(\"Text Vectorizer создан\")\n",
    "    print(f\"  Модель: {vectorizer.model}\")\n",
    "    \n",
    "    # Тестовая векторизация\n",
    "    texts = [\n",
    "        \"Машинное обучение\",\n",
    "        \"Искусственный интеллект\",\n",
    "        \"Погода сегодня\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nТексты для векторизации: {len(texts)}\")\n",
    "    \n",
    "    # Раскомментируйте для реального вызова:\n",
    "    embeddings = vectorizer.vectorize(texts)\n",
    "    print(f\"Эмбеддинги: {embeddings.shape}\")\n",
    "    \n",
    "    # Косинусное сходство первых двух\n",
    "    from numpy import dot\n",
    "    from numpy.linalg import norm\n",
    "    similarity = dot(embeddings[0], embeddings[1]) / (norm(embeddings[0]) * norm(embeddings[1]))\n",
    "    print(f\"Сходство 'ML' и 'AI': {similarity:.3f}\")\n",
    "    \n",
    "    print(\"\\nТребуется PyTorch и transformers\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование в GraphArchitect\n",
    "\n",
    "Использование локальных инструментов в полном workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphArchitect orchestrator инициализирован\n",
      "\n",
      "Можно использовать любые локальные инструменты в workflow\n",
      "Они будут автоматически интегрированы в граф и выбраны через softmax\n"
     ]
    }
   ],
   "source": [
    "from grapharchitect.services.execution.execution_orchestrator import ExecutionOrchestrator\n",
    "from grapharchitect.services.selection.instrument_selector import InstrumentSelector\n",
    "from grapharchitect.services.graph_strategy_finder import GraphStrategyFinder\n",
    "from grapharchitect.services.embedding.simple_embedding_service import SimpleEmbeddingService\n",
    "from grapharchitect.entities.task_definition import TaskDefinition\n",
    "from grapharchitect.entities.connectors.connector import Connector\n",
    "\n",
    "# Инициализация\n",
    "embedding = SimpleEmbeddingService(dimension=384)\n",
    "selector = InstrumentSelector(temperature_constant=1.0)\n",
    "finder = GraphStrategyFinder()\n",
    "orchestrator = ExecutionOrchestrator(embedding, selector, finder)\n",
    "\n",
    "print(\"GraphArchitect orchestrator инициализирован\")\n",
    "print(\"\\nМожно использовать любые локальные инструменты в workflow\")\n",
    "print(\"Они будут автоматически интегрированы в граф и выбраны через softmax\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоги\n",
    "\n",
    "**Локальные инструменты**:\n",
    "- Работают офлайн (без API)\n",
    "- Бесплатные (только GPU/CPU)\n",
    "- Privacy (данные не уходят)\n",
    "\n",
    "**Требования**:\n",
    "- PyTorch\n",
    "- Transformers\n",
    "- Модели Hugging Face\n",
    "- GPU рекомендуется\n",
    "\n",
    "**Применение**:\n",
    "- Когда нужна приватность\n",
    "- Когда нет интернета\n",
    "- Когда нужно сэкономить на API\n",
    "\n",
    "**См. также**: `03_integration_example.ipynb` для полных примеров интеграции"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
