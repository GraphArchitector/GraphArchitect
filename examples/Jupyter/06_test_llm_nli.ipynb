{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование LLM-based NLI\n",
    "\n",
    "NLI с использованием LLM для точного парсинга:\n",
    "- k-NN поиск похожих примеров\n",
    "- Few-shot промпт с примерами\n",
    "- LLM парсинг (OpenRouter/VLLM/DeepSeek)\n",
    "- JSON извлечение коннекторов\n",
    "\n",
    "Требуется: OPENROUTER_API_KEY (или VLLM сервер)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Статус:\n",
      "  OPENROUTER_API_KEY: ✓ Установлен\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "grapharchitect_path = Path.cwd().parent.parent / \"src\" / \"GraphArchitectLib\"\n",
    "sys.path.insert(0, str(grapharchitect_path))\n",
    "\n",
    "# Проверка API ключа\n",
    "HAS_API_KEY = bool(os.getenv('OPENROUTER_API_KEY'))\n",
    "\n",
    "print(\"Статус:\")\n",
    "print(f\"  OPENROUTER_API_KEY: {'✓ Установлен' if HAS_API_KEY else '✗ Не установлен'}\")\n",
    "\n",
    "if not HAS_API_KEY:\n",
    "    print(\"\\n⚠ Для работы установите: set OPENROUTER_API_KEY=your-key\")\n",
    "    print(\"  Или используйте VLLM: backend='vllm'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Создание датасета примеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создано примеров: 3\n",
      "  1. Классифицировать текст по категориям\n",
      "     text|question → text|category\n",
      "  2. Ответить на вопрос пользователя\n",
      "     text|question → text|answer\n",
      "  3. Создать статью по плану\n",
      "     text|outline → text|content\n"
     ]
    }
   ],
   "source": [
    "from grapharchitect.services.nli.nli_dataset_item import NLIDatasetItem\n",
    "from grapharchitect.services.embedding.simple_embedding_service import SimpleEmbeddingService\n",
    "from grapharchitect.entities.connectors.task_representation import TaskRepresentation\n",
    "from grapharchitect.entities.connectors.connector import Connector\n",
    "\n",
    "# Embedding service для k-NN\n",
    "embedding = SimpleEmbeddingService(dimension=384)\n",
    "\n",
    "# Создаем примеры для few-shot\n",
    "examples = []\n",
    "\n",
    "# Пример 1: Классификация\n",
    "rep1 = TaskRepresentation()\n",
    "rep1.input_connector = Connector(\"text\", \"question\")\n",
    "rep1.output_connector = Connector(\"text\", \"category\")\n",
    "\n",
    "examples.append(NLIDatasetItem(\n",
    "    task_text=\"Классифицировать текст по категориям\",\n",
    "    task_embedding=embedding.embed_text(\"Классифицировать текст\"),\n",
    "    representation=rep1\n",
    "))\n",
    "\n",
    "# Пример 2: QA\n",
    "rep2 = TaskRepresentation()\n",
    "rep2.input_connector = Connector(\"text\", \"question\")\n",
    "rep2.output_connector = Connector(\"text\", \"answer\")\n",
    "\n",
    "examples.append(NLIDatasetItem(\n",
    "    task_text=\"Ответить на вопрос пользователя\",\n",
    "    task_embedding=embedding.embed_text(\"Ответить на вопрос\"),\n",
    "    representation=rep2\n",
    "))\n",
    "\n",
    "# Пример 3: Генерация\n",
    "rep3 = TaskRepresentation()\n",
    "rep3.input_connector = Connector(\"text\", \"outline\")\n",
    "rep3.output_connector = Connector(\"text\", \"content\")\n",
    "\n",
    "examples.append(NLIDatasetItem(\n",
    "    task_text=\"Создать статью по плану\",\n",
    "    task_embedding=embedding.embed_text(\"Создать статью\"),\n",
    "    representation=rep3\n",
    "))\n",
    "\n",
    "print(f\"Создано примеров: {len(examples)}\")\n",
    "for i, ex in enumerate(examples, 1):\n",
    "    print(f\"  {i}. {ex.task_text}\")\n",
    "    print(f\"     {ex.representation.input_connector.format} → {ex.representation.output_connector.format}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Инициализация LLM NLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:grapharchitect.tools.ApiTools.OpenRouterTool.openrouter_llm:OpenRouter инициализирован: модель openai/gpt-3.5-turbo\n",
      "INFO:grapharchitect.services.nli.llm_nli_service:OpenRouter backend initialized\n",
      "INFO:grapharchitect.services.nli.llm_nli_service:LLM NLI initialized: openrouter with openai/gpt-3.5-turbo\n",
      "INFO:grapharchitect.services.nli.llm_nli_service:Loaded 3 NLI examples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ LLM NLI инициализирован\n",
      "  Backend: OpenRouter\n",
      "  Модель: gpt-3.5-turbo\n",
      "  Датасет: 3 примеров\n"
     ]
    }
   ],
   "source": [
    "if HAS_API_KEY:\n",
    "    from grapharchitect.services.nli.llm_nli_service import LLMNLIService\n",
    "    \n",
    "    # Создание LLM NLI с OpenRouter\n",
    "    llm_nli = LLMNLIService(\n",
    "        embedding_service=embedding,\n",
    "        backend=\"openrouter\",\n",
    "        model_name=\"openai/gpt-3.5-turbo\",\n",
    "        k_similar=3,\n",
    "        temperature=0.1  # Низкая для точности\n",
    "    )\n",
    "    \n",
    "    # Загрузка датасета\n",
    "    llm_nli.load_dataset(examples)\n",
    "    \n",
    "    print(\"✓ LLM NLI инициализирован\")\n",
    "    print(f\"  Backend: OpenRouter\")\n",
    "    print(f\"  Модель: gpt-3.5-turbo\")\n",
    "    print(f\"  Датасет: {len(examples)} примеров\")\n",
    "else:\n",
    "    print(\"⚠ Установите OPENROUTER_API_KEY для работы\")\n",
    "    llm_nli = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Создание демо инструментов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создано инструментов: 3\n",
      "  Classifier: text|question → text|category\n",
      "  QA-System: text|question → text|answer\n",
      "  Writer: text|outline → text|content\n"
     ]
    }
   ],
   "source": [
    "from grapharchitect.entities.base_tool import BaseTool\n",
    "\n",
    "class DemoTool(BaseTool):\n",
    "    def __init__(self, name, input_fmt, output_fmt):\n",
    "        super().__init__()\n",
    "        self.metadata.tool_name = name\n",
    "        \n",
    "        inp = input_fmt.split(\"|\")\n",
    "        out = output_fmt.split(\"|\")\n",
    "        \n",
    "        self.input = Connector(inp[0], inp[1])\n",
    "        self.output = Connector(out[0], out[1])\n",
    "    \n",
    "    def execute(self, input_data):\n",
    "        return \"Success\"\n",
    "\n",
    "# Создаем набор инструментов\n",
    "tools = [\n",
    "    DemoTool(\"Classifier\", \"text|question\", \"text|category\"),\n",
    "    DemoTool(\"QA-System\", \"text|question\", \"text|answer\"),\n",
    "    DemoTool(\"Writer\", \"text|outline\", \"text|content\"),\n",
    "]\n",
    "\n",
    "print(f\"Создано инструментов: {len(tools)}\")\n",
    "for tool in tools:\n",
    "    print(f\"  {tool.metadata.tool_name}: {tool.input.format} → {tool.output.format}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Тестирование парсинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестирование LLM NLI:\n",
      "\n",
      "Запрос: \"Определить категорию этого текста\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:grapharchitect.tools.ApiTools.OpenRouterTool.openrouter_llm:Использовано токенов: prompt=347, completion=50, total=397\n",
      "INFO:grapharchitect.services.nli.llm_nli_service:LLM NLI parsed: text|content → text|category\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Вход:  text|content\n",
      "  Выход: text|category\n",
      "  Уверенность: 0.85\n",
      "  Использовано примеров из k-NN: 3\n",
      "\n",
      "Запрос: \"Дать ответ на вопрос клиента\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:grapharchitect.tools.ApiTools.OpenRouterTool.openrouter_llm:Использовано токенов: prompt=344, completion=50, total=394\n",
      "INFO:grapharchitect.services.nli.llm_nli_service:LLM NLI parsed: text|question → text|answer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Вход:  text|question\n",
      "  Выход: text|answer\n",
      "  Уверенность: 0.85\n",
      "  Использовано примеров из k-NN: 3\n",
      "\n",
      "Запрос: \"Написать статью по плану\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:grapharchitect.tools.ApiTools.OpenRouterTool.openrouter_llm:Использовано токенов: prompt=347, completion=50, total=397\n",
      "INFO:grapharchitect.services.nli.llm_nli_service:LLM NLI parsed: text|outline → text|content\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Вход:  text|outline\n",
      "  Выход: text|content\n",
      "  Уверенность: 0.85\n",
      "  Использовано примеров из k-NN: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Тестовые запросы\n",
    "test_queries = [\n",
    "    \"Определить категорию этого текста\",\n",
    "    \"Дать ответ на вопрос клиента\",\n",
    "    \"Написать статью по плану\"\n",
    "]\n",
    "\n",
    "if HAS_API_KEY and llm_nli:\n",
    "    print(\"Тестирование LLM NLI:\\n\")\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"Запрос: \\\"{query}\\\"\")\n",
    "        \n",
    "        # Парсинг через LLM\n",
    "        result = llm_nli.parse_task(query, tools, k=3)\n",
    "        \n",
    "        if result.success:\n",
    "            rep = result.task_representation\n",
    "            print(f\"  Вход:  {rep.input_connector.format}\")\n",
    "            print(f\"  Выход: {rep.output_connector.format}\")\n",
    "            print(f\"  Уверенность: {result.confidence:.2f}\")\n",
    "            \n",
    "            # Показываем использованные примеры\n",
    "            if result.similar_examples:\n",
    "                print(f\"  Использовано примеров из k-NN: {len(result.similar_examples)}\")\n",
    "        else:\n",
    "            print(f\"  ✗ Ошибка: {result.error_message}\")\n",
    "        \n",
    "        print()\n",
    "else:\n",
    "    print(\"Для теста установите OPENROUTER_API_KEY\")\n",
    "    print(\"\\nОжидаемые результаты:\")\n",
    "    print(\"  1. 'Определить категорию' → text|question → text|category\")\n",
    "    print(\"  2. 'Дать ответ' → text|question → text|answer\")\n",
    "    print(\"  3. 'Написать статью' → text|outline → text|content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Сравнение k-NN vs LLM NLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сравнение k-NN NLI vs LLM NLI:\n",
      "\n",
      "Запрос: \"Категоризировать сообщение пользователя\"\n",
      "\n",
      "k-NN NLI:\n",
      "  text|outline → text|content\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:grapharchitect.tools.ApiTools.OpenRouterTool.openrouter_llm:Использовано токенов: prompt=343, completion=50, total=393\n",
      "INFO:grapharchitect.services.nli.llm_nli_service:LLM NLI parsed: text|question → text|category\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM NLI:\n",
      "  text|question → text|category\n",
      "\n",
      "Результаты различаются\n"
     ]
    }
   ],
   "source": [
    "# k-NN NLI (базовый)\n",
    "from grapharchitect.services.nli.natural_language_interface import NaturalLanguageInterface\n",
    "\n",
    "knn_nli = NaturalLanguageInterface(embedding)\n",
    "knn_nli.load_dataset(examples)\n",
    "\n",
    "print(\"Сравнение k-NN NLI vs LLM NLI:\\n\")\n",
    "\n",
    "test_query = \"Категоризировать сообщение пользователя\"\n",
    "\n",
    "# k-NN подход\n",
    "print(f\"Запрос: \\\"{test_query}\\\"\\n\")\n",
    "\n",
    "knn_result = knn_nli.parse_task(test_query, tools, k=3)\n",
    "\n",
    "print(\"k-NN NLI:\")\n",
    "if knn_result.success:\n",
    "    print(f\"  {knn_result.task_representation.input_connector.format} → {knn_result.task_representation.output_connector.format}\")\n",
    "else:\n",
    "    print(f\"  Ошибка\")\n",
    "\n",
    "# LLM подход\n",
    "if HAS_API_KEY and llm_nli:\n",
    "    llm_result = llm_nli.parse_task(test_query, tools, k=3)\n",
    "    \n",
    "    print(\"\\nLLM NLI:\")\n",
    "    if llm_result.success:\n",
    "        print(f\"  {llm_result.task_representation.input_connector.format} → {llm_result.task_representation.output_connector.format}\")\n",
    "    else:\n",
    "        print(f\"  Ошибка\")\n",
    "    \n",
    "    # Сравнение\n",
    "    if knn_result.success and llm_result.success:\n",
    "        same = (knn_result.task_representation.input_connector.format == llm_result.task_representation.input_connector.format and\n",
    "                knn_result.task_representation.output_connector.format == llm_result.task_representation.output_connector.format)\n",
    "        \n",
    "        print(f\"\\nРезультаты {'совпадают' if same else 'различаются'}\")\n",
    "else:\n",
    "    print(\"\\nLLM NLI: Требуется API ключ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Интеграция с GraphArchitect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Естественный запрос: \"Проклассифицировать этот отзыв клиента\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:grapharchitect.tools.ApiTools.OpenRouterTool.openrouter_llm:Использовано токенов: prompt=351, completion=50, total=401\n",
      "INFO:grapharchitect.services.nli.llm_nli_service:LLM NLI parsed: text|content → text|category\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM NLI распарсил:\n",
      "  Вход: text|content\n",
      "  Выход: text|category\n",
      "start_format text|content text|category\n",
      "\n",
      "Выполнение:\n",
      "  Статус: failed\n",
      "  Ошибка: Не найдено путей от входного к выходному коннектору\n",
      "  Результат: None\n",
      "\n",
      "✓ Полный цикл: Естественный язык → NLI → GraphArchitect → Результат\n"
     ]
    }
   ],
   "source": [
    "if HAS_API_KEY and llm_nli:\n",
    "    from grapharchitect.services.execution.execution_orchestrator import ExecutionOrchestrator\n",
    "    from grapharchitect.services.selection.instrument_selector import InstrumentSelector\n",
    "    from grapharchitect.services.graph_strategy_finder import GraphStrategyFinder\n",
    "    from grapharchitect.services.pathfinding_algorithm import PathfindingAlgorithm\n",
    "    from grapharchitect.entities.task_definition import TaskDefinition\n",
    "    \n",
    "    # Инициализация\n",
    "    selector = InstrumentSelector(temperature_constant=1.0)\n",
    "    finder = GraphStrategyFinder()\n",
    "    orchestrator = ExecutionOrchestrator(embedding, selector, finder)\n",
    "    \n",
    "    # Генерация эмбеддингов для инструментов\n",
    "    for tool in tools:\n",
    "        tool.metadata.capabilities_embedding = embedding.embed_tool_capabilities(tool)\n",
    "    \n",
    "    # Задача на естественном языке\n",
    "    natural_query = \"Проклассифицировать этот отзыв клиента\"\n",
    "    \n",
    "    print(f\"Естественный запрос: \\\"{natural_query}\\\"\\n\")\n",
    "    \n",
    "    # LLM NLI парсинг\n",
    "    nli_result = llm_nli.parse_task(natural_query, tools)\n",
    "    \n",
    "    if nli_result.success:\n",
    "        rep = nli_result.task_representation\n",
    "        \n",
    "        print(\"LLM NLI распарсил:\")\n",
    "        print(f\"  Вход: {rep.input_connector.format}\")\n",
    "        print(f\"  Выход: {rep.output_connector.format}\")\n",
    "        \n",
    "        # Создание задачи с распарсенными коннекторами\n",
    "        task = TaskDefinition(\n",
    "            description=natural_query,\n",
    "            input_connector=rep.input_connector,\n",
    "            output_connector=rep.output_connector,\n",
    "            input_data=\"Отличный продукт!\"\n",
    "        )\n",
    "        \n",
    "        # Выполнение\n",
    "        context = orchestrator.execute_task(task, tools, path_limit=2, top_k=2)\n",
    "        #, algorithm=PathfindingAlgorithm.ANT_COLONY\n",
    "        \n",
    "        print(f\"\\nВыполнение:\")\n",
    "        print(f\"  Статус: {context.status.value}\")\n",
    "        print(f\"  Ошибка: {context.error_message}\")\n",
    "        print(f\"  Результат: {context.result}\")\n",
    "        print(f\"\\n✓ Полный цикл: Естественный язык → NLI → GraphArchitect → Результат\")\n",
    "    else:\n",
    "        print(f\"✗ LLM NLI не смог распарсить: {nli_result.error_message}\")\n",
    "else:\n",
    "    print(\"Для теста установите OPENROUTER_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоги\n",
    "\n",
    "**LLM-based NLI реализован**:\n",
    "- ✓ k-NN поиск похожих примеров\n",
    "- ✓ Few-shot промпт (динамический)\n",
    "- ✓ LLM парсинг (OpenRouter/VLLM/DeepSeek)\n",
    "- ✓ JSON извлечение коннекторов\n",
    "- ✓ Интеграция с GraphArchitect\n",
    "\n",
    "**Преимущества vs k-NN**:\n",
    "- Более точный парсинг (LLM понимает контекст)\n",
    "- Работает на новых типах задач\n",
    "- Few-shot адаптируется к запросу\n",
    "\n",
    "**Преимущества vs fine-tuned модель**:\n",
    "- Не требует дообучения\n",
    "- Легко обновлять (новые примеры в датасет)\n",
    "- Работает с любой LLM\n",
    "\n",
    "**Применение**:\n",
    "- Production NLI (с OpenRouter)\n",
    "- Privacy (с VLLM локально)\n",
    "- Высокая точность (с GPT-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
